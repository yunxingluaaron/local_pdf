{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:9200\n",
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"GET /_security/role/aaronlu_full_access HTTP/11\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:GET http://localhost:9200/_security/role/aaronlu_full_access [status:200 duration:0.029s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the es status is <Elasticsearch(['http://localhost:9200'])>\n",
      "Role already exists: {'aaronlu_full_access': {'cluster': ['all'], 'indices': [{'names': ['*'], 'privileges': ['all'], 'allow_restricted_indices': False}], 'applications': [{'application': '*', 'privileges': ['*'], 'resources': ['*']}], 'run_as': [], 'metadata': {}, 'transient_metadata': {'enabled': True}}}\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[\"http://localhost:9200\"],\n",
    "    basic_auth=('elastic', os.getenv('ES_PASSWORD', 'Lyx19930115'))\n",
    ")\n",
    "\n",
    "print(f\"the es status is {es}\")\n",
    "\n",
    "# Define the role with full access\n",
    "role_name = \"aaronlu_full_access\"\n",
    "try:\n",
    "    # First check if role exists\n",
    "    existing_role = es.security.get_role(name=role_name)\n",
    "    print(f\"Role already exists: {existing_role}\")\n",
    "except Exception as e:\n",
    "    # If role doesn't exist, create it\n",
    "    role_body = {\n",
    "        \"cluster\": [\"all\"],\n",
    "        \"indices\": [\n",
    "            {\n",
    "                \"names\": [\"*\"],\n",
    "                \"privileges\": [\"all\"]\n",
    "            }\n",
    "        ],\n",
    "        \"applications\": [\n",
    "            {\n",
    "                \"application\": \"*\",\n",
    "                \"privileges\": [\"*\"],\n",
    "                \"resources\": [\"*\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = es.security.put_role(name=role_name, body=role_body)\n",
    "        print(f\"Role creation response: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating role: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"POST /default/_search HTTP/11\" 200 None\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/default/_search [status:200 duration:0.135s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking index contents...\n",
      "Total documents in index: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking index contents...\")\n",
    "response = es.search(\n",
    "    index=\"default\",\n",
    "    body={\"query\": {\"match_all\": {}}}\n",
    ")\n",
    "print(f\"Total documents in index: {response['hits']['total']['value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"POST /default/_search HTTP/11\" 200 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:elastic_transport.transport:POST http://localhost:9200/default/_search [status:200 duration:0.024s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking document keys...\n",
      "\n",
      "Document keys structure:\n",
      "patent_index\n",
      "chunks\n",
      "    chunk_index\n",
      "    text\n",
      "    embedding\n",
      "    is_claims\n",
      "    is_abstract\n",
      "    is_patentability\n",
      "    is_fto\n"
     ]
    }
   ],
   "source": [
    "def print_nested_keys(data, prefix=''):\n",
    "    \"\"\"Recursively print all keys in a nested dictionary\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            print(f\"{prefix}{key}\")\n",
    "            if isinstance(value, (dict, list)):\n",
    "                print_nested_keys(value, prefix + '  ')\n",
    "    elif isinstance(data, list) and len(data) > 0:\n",
    "        # For lists, check the first item's structure\n",
    "        print_nested_keys(data[0], prefix + '  ')\n",
    "\n",
    "# Check document structure and keys\n",
    "print(\"Checking document keys...\")\n",
    "response = es.search(\n",
    "    index=\"default\",\n",
    "    body={\"query\": {\"match_all\": {}}}\n",
    ")\n",
    "\n",
    "for hit in response['hits']['hits'][:1]:\n",
    "    print(\"\\nDocument keys structure:\")\n",
    "    print_nested_keys(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"HEAD /test_patent_index HTTP/11\" 404 0\n",
      "INFO:elastic_transport.transport:HEAD http://localhost:9200/test_patent_index [status:404 duration:0.005s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"PUT /test_patent_index HTTP/11\" 200 0\n",
      "INFO:elastic_transport.transport:PUT http://localhost:9200/test_patent_index [status:200 duration:0.711s]\n",
      "INFO:__main__:Created index: test_patent_index\n",
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"PUT /test_patent_index/_doc/1 HTTP/11\" 201 0\n",
      "INFO:elastic_transport.transport:PUT http://localhost:9200/test_patent_index/_doc/1 [status:201 duration:0.034s]\n",
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"POST /test_patent_index/_refresh HTTP/11\" 200 0\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/test_patent_index/_refresh [status:200 duration:0.103s]\n",
      "INFO:__main__:Inserted test document\n",
      "INFO:__main__:Testing BM25 search with query: machine learning\n",
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"POST /test_patent_index/_search HTTP/11\" 200 None\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/test_patent_index/_search [status:200 duration:0.012s]\n",
      "INFO:__main__:BM25 search returned 1 hits\n",
      "INFO:__main__:Testing semantic search\n",
      "DEBUG:urllib3.connectionpool:http://localhost:9200 \"POST /test_patent_index/_search HTTP/11\" 200 None\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/test_patent_index/_search [status:200 duration:0.015s]\n",
      "INFO:__main__:Semantic search returned 1 hits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing BM25 Search:\n",
      "BM25 Results: [\n",
      "  {\n",
      "    \"patent_id\": \"TEST123\",\n",
      "    \"chunk_index\": 0,\n",
      "    \"text\": \"This is a test patent about machine learning technology.\",\n",
      "    \"score\": 1.8658177\n",
      "  }\n",
      "]\n",
      "\n",
      "Testing Semantic Search:\n",
      "Semantic Results: [\n",
      "  {\n",
      "    \"patent_id\": \"TEST123\",\n",
      "    \"chunk_index\": 0,\n",
      "    \"text\": \"This is a test patent about machine learning technology.\",\n",
      "    \"score\": 1.999991\n",
      "  },\n",
      "  {\n",
      "    \"patent_id\": \"TEST123\",\n",
      "    \"chunk_index\": 1,\n",
      "    \"text\": \"The invention relates to artificial intelligence systems.\",\n",
      "    \"score\": 1.999991\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from elasticsearch import Elasticsearch\n",
    "import logging\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Test data to insert\n",
    "test_document = {\n",
    "    \"patent_index\": \"TEST123\",\n",
    "    \"chunks\": [\n",
    "        {\n",
    "            \"chunk_index\": 0,\n",
    "            \"text\": \"This is a test patent about machine learning technology.\",\n",
    "            \"is_abstract\": True,\n",
    "            \"is_patentability\": True,\n",
    "            \"is_claims\": True,\n",
    "            \"embedding\": [0.1] * 1536  # Assuming your embedding size is 1536\n",
    "        },\n",
    "        {\n",
    "            \"chunk_index\": 1,\n",
    "            \"text\": \"The invention relates to artificial intelligence systems.\",\n",
    "            \"is_abstract\": True,\n",
    "            \"is_patentability\": True,\n",
    "            \"is_claims\": True,\n",
    "            \"embedding\": [0.2] * 1536\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to create test index and insert test data\n",
    "def setup_test_index():\n",
    "    index_name = \"test_patent_index\"\n",
    "    \n",
    "    # Delete index if it exists\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "    \n",
    "    # Create index with mapping\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"patent_index\": {\"type\": \"keyword\"},\n",
    "                \"chunks\": {\n",
    "                    \"type\": \"nested\",\n",
    "                    \"properties\": {\n",
    "                        \"chunk_index\": {\"type\": \"integer\"},\n",
    "                        \"text\": {\"type\": \"text\"},\n",
    "                        \"is_abstract\": {\"type\": \"boolean\"},\n",
    "                        \"is_patentability\": {\"type\": \"boolean\"},\n",
    "                        \"is_claims\": {\"type\": \"boolean\"},\n",
    "                        \"embedding\": {\n",
    "                            \"type\": \"dense_vector\",\n",
    "                            \"dims\": 1536,\n",
    "                            \"index\": True,\n",
    "                            \"similarity\": \"cosine\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    logger.info(f\"Created index: {index_name}\")\n",
    "    \n",
    "    # Insert test document\n",
    "    es.index(index=index_name, id=1, body=test_document)\n",
    "    es.indices.refresh(index=index_name)\n",
    "    logger.info(\"Inserted test document\")\n",
    "    \n",
    "    return index_name\n",
    "\n",
    "# Test BM25 search\n",
    "def test_bm25_search(index_name, query_text):\n",
    "    logger.info(f\"Testing BM25 search with query: {query_text}\")\n",
    "    \n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"chunks\",\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\"match\": {\"chunks.text\": query_text}},\n",
    "                            {\"term\": {\"chunks.is_abstract\": True}},\n",
    "                            {\"term\": {\"chunks.is_patentability\": True}},\n",
    "                            {\"term\": {\"chunks.is_claims\": True}}\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"size\": 5\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"patent_index\"]\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=query)\n",
    "    logger.info(f\"BM25 search returned {len(response['hits']['hits'])} hits\")\n",
    "    \n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        patent_index = hit['_source']['patent_index']\n",
    "        for inner_hit in hit['inner_hits']['chunks']['hits']['hits']:\n",
    "            chunk = inner_hit['_source']\n",
    "            results.append({\n",
    "                \"patent_id\": str(patent_index),\n",
    "                \"chunk_index\": chunk['chunk_index'],\n",
    "                \"text\": chunk['text'],\n",
    "                \"score\": inner_hit['_score']\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test semantic search\n",
    "def test_semantic_search(index_name, query_embedding):\n",
    "    logger.info(\"Testing semantic search\")\n",
    "    \n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"chunks\",\n",
    "                \"query\": {\n",
    "                    \"script_score\": {\n",
    "                        \"query\": {\n",
    "                            \"bool\": {\n",
    "                                \"must\": [\n",
    "                                    {\"term\": {\"chunks.is_abstract\": True}},\n",
    "                                    {\"term\": {\"chunks.is_patentability\": True}},\n",
    "                                    {\"term\": {\"chunks.is_claims\": True}}\n",
    "                                ]\n",
    "                            }\n",
    "                        },\n",
    "                        \"script\": {\n",
    "                            \"source\": \"cosineSimilarity(params.query_vector, 'chunks.embedding') + 1.0\",\n",
    "                            \"params\": {\"query_vector\": query_embedding}\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"size\": 5\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"patent_index\"]\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=query)\n",
    "    logger.info(f\"Semantic search returned {len(response['hits']['hits'])} hits\")\n",
    "    \n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        patent_index = hit['_source']['patent_index']\n",
    "        for inner_hit in hit['inner_hits']['chunks']['hits']['hits']:\n",
    "            chunk = inner_hit['_source']\n",
    "            results.append({\n",
    "                \"patent_id\": str(patent_index),\n",
    "                \"chunk_index\": chunk['chunk_index'],\n",
    "                \"text\": chunk['text'],\n",
    "                \"score\": hit['_score']\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run tests\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup test index and data\n",
    "    test_index = setup_test_index()\n",
    "    \n",
    "    # Test queries\n",
    "    test_query = \"machine learning\"\n",
    "    test_embedding = [0.1] * 1536  # Simple test embedding\n",
    "    \n",
    "    print(\"\\nTesting BM25 Search:\")\n",
    "    bm25_results = test_bm25_search(test_index, test_query)\n",
    "    print(f\"BM25 Results: {json.dumps(bm25_results, indent=2)}\")\n",
    "    \n",
    "    print(\"\\nTesting Semantic Search:\")\n",
    "    semantic_results = test_semantic_search(test_index, test_embedding)\n",
    "    print(f\"Semantic Results: {json.dumps(semantic_results, indent=2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_pdf_upload_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
